{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='TableOfContents'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "1. Please run the first two cells as is to load libraries\n",
    "2. The code guides and output will help you develop your code\n",
    "3. in case your results are not matching the previous output (left for you) this could be due to randomization and you should not worry about them\n",
    "4. Most of the code is ready,  all you need to do in fill in some parts of the codes to complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import  make_regression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, SplineTransformer # incase of error update sklearn to v1.0\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Question1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 (Build simple regression using manual data)\n",
    "\n",
    "1. Generate dataset (manually)\n",
    "    - Generate random data, one independent variable, 20 samples (X)\n",
    "    - Then, randomly choose c and m, where C is the intercept and m is the Coefficient(slope).\n",
    "    - Generate the dependent variable (**y**) applying the  equation \n",
    "\n",
    "        $y = C + m. x + \\epsilon$ , where $\\epsilon$ is some random error\n",
    "\n",
    "2. Develop a Python function (**estimate_Coef(x, y)** ) that estimates \\beta_0 , \\beta_1 using the slide equations:\n",
    "\n",
    " $\\beta_1 = \\frac{(n \\sum_i{x_iy_i} - \\sum_i{x_i} \\sum_i{y_i})}{(n \\sum_i{x_i^2} - (\\sum_i{x_i})^2 )}$\n",
    "\n",
    " $\\beta_0 = \\frac{1}{n} \\sum_i{y_i} - \\frac{\\beta_1}{n} \\sum_i{x_i} $\n",
    "\n",
    "\n",
    "where \\beta_0 is an estimate for the intercept, and \\beta_1 is an estimate to the slope. x and y are the\n",
    "independent and dependent variables respectively\n",
    "\n",
    "\n",
    "3. We want to use our developed function to estimate the C and m from the data compared to the original C and m\n",
    "5. To draw the regression line:\n",
    "    - Compute the predictions for each data point. This must be a regression line that represents the mean of the data\n",
    "    - Scatter plot the original data (X, y), then plot a line using (X, y_predicted) \n",
    "\n",
    "[Return to Table of Contents](#TableOfContents)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data std: 0.849337085693721\n"
     ]
    }
   ],
   "source": [
    "# Task 1 : Generate some data\n",
    "# any random seed let us pick \n",
    "np.random.seed(40)\n",
    "\n",
    "# use randn from np.random to pick 20 random values for data \n",
    "# phonminana error\n",
    "err = np.random.randn( 5) # add value between brackts to complete this code line\n",
    "\n",
    "# Also, pick 20 random value for X (indpendent variable)\n",
    "X = np.random.randn(2,5)              # complete this code line similar to err line above\n",
    "\n",
    "\n",
    "print('data std:', np.std(X) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 2: Randomly choose  intercept and Slope \n",
    "# it has to be real value greater than 1\n",
    "# format:  np has rand and randint \n",
    "# the rand function will draw a value from 0 to 1 \n",
    "# the ranint will draw an integer value\n",
    "\n",
    "# let use randomly choose intercept c or b0 using choice from np.random\n",
    "# format: choice method select a value from a list \n",
    "# use rand + randint to make that list\n",
    "c   = np.random.choice(   X       +     err   ) # complete this line \n",
    "\n",
    "# let use randomly choose intercept m or b1 using choice from np.random\n",
    "# similar to c line\n",
    "m  = np.random.choice(        +       ) # compelete this line\n",
    "\n",
    "print('c=', c, 'and m =', m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us compute the response y (true)\n",
    "\n",
    "y =      # complete this line of code\n",
    "\n",
    "# plot the generated data\n",
    "\n",
    "# write your plotting code here\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Define a Python function (estimate_Coef(x, y) )that estimates the coffecients\n",
    "# define or build a function\n",
    "\n",
    "def estimate_coef(X,y): # fun header done for you\n",
    "    \n",
    "   #get size of samples in X\n",
    "    n =   # complete the code here\n",
    "    \n",
    "  #Convert the slide questions to python for b1 and b0 \n",
    "  # use slides equation and convert it to python code\n",
    "    # for summation using np.sum\n",
    "    # for average using np.mean\n",
    "    # for squaring use **\n",
    "    # make sure of the right brackts to enforce calculation\n",
    "    b1 =   # complete this code\n",
    "    b0 =   # complete this code\n",
    "    \n",
    "    # return coeficients b0 and b1\n",
    "    return (b0, b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Pass the generated data in steps 1 and 2 to the estimate_Coef()\n",
    "# calling a function is very easy, we need to write the name of a function and pass the params\n",
    "# call estimate_coef to get b1 an b0\n",
    "\n",
    "b0, b1 = # complete the code here\n",
    "\n",
    "print('Estimated Coefients: b0=%0.2f, b1=%0.2f'% (b0, b1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***********\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5: Use these coefficients to compute y_pred using the data in X only\n",
    "\n",
    "# To compute the the response we need to use the params b0 and b1 with X values\n",
    "y_pred = # complete the code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 6: Draw the regression line over scattered data plot.\n",
    "# figure size\n",
    "plt.Figure(figsize=(10,8))\n",
    "\n",
    "# scater plot the data X and y\n",
    "plt.scatter(   ,   , c='b') # complete the code ( 2 params )\n",
    "\n",
    "# plot a model line over the scattered data (use y_pred!)\n",
    "plt.plot(   ,   ,c='r') # complete the code ( 2 params )\n",
    "\n",
    "plt.xlabel('Idependent Variable')\n",
    "plt.ylabel('Response')\n",
    "plt.grid()\n",
    "plt.title('Dataset  - BLue')\n",
    "\n",
    "plt.tight_layout(rect=(0,0,1.2,1.5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "The model line is perfectly passes through the avg of the data. Hopefully new datapoints will follow this trend in future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='Question2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 (Explore and practice Sklearn Regression modules)\n",
    "\n",
    "Import the linear regression package from Scikit learn library. Then, for each dataset from the previous question fit a linear regression. Get both the intercept and coefficient values from the trained models and compare it with your results in the previous question.\n",
    "\n",
    "\n",
    "\n",
    "[Return to Table of Contents](#TableOfContents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the LinearRegression model from linear_model module\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need first to instantiate the model or make an object of the class Linear..\n",
    "\n",
    "# instantiate the model LinearRegression\n",
    "Lr = # complete this line\n",
    "\n",
    "# As the data is 1D, sklearn will complain to have 2D data\n",
    "# you need to reshape your data using .reshape(-1, 1)\n",
    "# this means arrange my data with any number of rows but add another dimension to it\n",
    "# another method is [:, None]\n",
    "\n",
    "# Train (fit) the model\n",
    "Lr.   # complete code here \n",
    "\n",
    "print('A model is created and trained successfully ..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the model coeficients\n",
    "# we can access the model params using the Lr we built\n",
    "# it saves the params in intercept_ and coef_\n",
    "\n",
    "model_b0 = Lr.  # complete the code here\n",
    "model_b1 = Lr.  # complete the code here\n",
    "\n",
    "\n",
    "print('dataset1:\\nSklearn:b0=%0.2f wraper:b0=%0.2f\\nSklearn:b1=%0.2f wraper:b1=%0.2f'%(model_b0, b0, model_b1, b1 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "The coefficients are exactly the same. Linear Regression model in sklearn uses the closed form solution. There is another version with estimates the coefficients using gradient descent algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the results, the prediction will be used directly\n",
    "plt.figure(figsize=(10,3) )\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(  ,  , c='b') # compelte the code here\n",
    "plt.plot(   ,    , c='r')  # compelte the code here\n",
    "plt.xlabel('Idependent Variable', fontsize=14)\n",
    "plt.ylabel('Response', fontsize=14)\n",
    "plt.title('With Sklearn', fontsize=16)\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(  ,  , c='g') # compelte the code here\n",
    "plt.plot(  ,   , c='r') # compelte the code here\n",
    "plt.title('With wraper', fontsize=16)\n",
    "plt.xlabel('Idependent Variable', fontsize=14)\n",
    "plt.ylabel('Response', fontsize=14)\n",
    "\n",
    "# make sure it shows nice\n",
    "plt.tight_layout(rect=(0,0,1.2,1.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 ( Load Boston dataset )\n",
    "\n",
    "We want to answer the question raised in the slides and estimate the house price for house with 6-bedroom size. We need to build a regression model using the Boston house dataset and consider only RM as the independent variable, while price (target) is the response from this model. \n",
    "\n",
    "**Note:** The Boston dataset will be deprecated in future, so you can load the dataset from a course file. \n",
    "\n",
    "\n",
    "[Return to Table of Contents](#TableOfContents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the Boston housing dataset\n",
    "boston = load_boston()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset has a dictionary structure\n",
    "# so to access information we need use use keys\n",
    "# so let us check the keys\n",
    "\n",
    "boston.   # complete the code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above keys, \n",
    "1. we can access the data (matrix form), \n",
    "1. a target (1xn size) for each record in the data\n",
    "1. feature_names can be listed \n",
    "1. detailed description can be accessed using DESCR\n",
    "1. filename a local path to the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us check all  features\n",
    "print('Features:\\n', boston.  ) # complete the code here ( boston. needs a key)\n",
    "\n",
    "print('\\n\\nWe need only RM feature to build our model in this exercise!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Linear Regression model using RM feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an Lr1 model\n",
    "# instantiate the regression model \n",
    "Lr1 = # complete the code here\n",
    "\n",
    "# to build a model using only roomsize or rm, you need to extract rm from the data or\n",
    "# pass (slice) the RM index data (rm index is 5), also you need to reshape(-1,1). Sklearn expects 2d array\n",
    "\n",
    "# train the model\n",
    "Lr1.fit(          ,      ) # complete the code here\n",
    "\n",
    "\n",
    "print('training finished, and a LR model is created with RM as input ..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us plot the data and the model\n",
    "\n",
    "plt.scatter( ,   , c='g') # complete the code here ( 2 params are missing)\n",
    "\n",
    "# our target size\n",
    "plt.axvline(x = 6.0, color='k', linestyle='--')\n",
    "\n",
    "# plot red line for Lr1 model\n",
    "plt.plot(  ,    , c='r' ) # complete the code here ( 2 params are missing)\n",
    "\n",
    "\n",
    "plt.xlabel('Room Sizes', fontsize=15)\n",
    "plt.ylabel('House Prices', fontsize=15)\n",
    "plt.title('Boston dataset (Room size problem)', fontsize=18)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the 6-bedroom house price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To estimate a new house, we need to input the value between two brackets [[value ]]\n",
    "\n",
    "# Estimate the house with 6 bedrooms\n",
    "EstPrice =   # complete the code here \n",
    "\n",
    "\n",
    "print(\"My program estimates your house's price as:{0:0.2f}K$\".format(EstPrice[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This way, we can estimate any house price based on its size** \n",
    "\n",
    "we can estimate a batch of houses at once by passing the RM sizes as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch houses predictions\n",
    "# we can inqure several houses with sizes 5, 6, 7, 9\n",
    "# np array 2d\n",
    "houses =  # complete the code here\n",
    "EstPrice = Lr1.predict(houses)\n",
    "\n",
    "\n",
    "print('houses sizes:',houses)\n",
    "print(\"Prices\", EstPrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='Question3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Exercise 4 ( Identify which features less not important)\n",
    "\n",
    "\n",
    "Scikit learn allow us to generate multi-feature regression data using **make_regression** method. The make_regression has several parameters to configure to satisfy your needs and study the regression models. In this exercise, we want to generate some regression data with 10 features. Some of these feature should be not related (non informative).  Then, we want to build a regression model and study the regression coefficients to identify which features are not informative?\n",
    "\n",
    "1. Configure the **n_informative** parameter with the following equation \n",
    "\n",
    "                n\\_informative = np.random.randint(9) + 1 \n",
    "\n",
    ", so we don't know how many of the features are not informative!\n",
    "\n",
    "2. Then, build a regression model as we did in the previous exercises, and find out the regression coefficients, and \n",
    "5. Determine which features can be neglected!! \n",
    "\n",
    "\n",
    "[Return to Table of Contents](#TableOfContents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# we can generate a regression data as follow\n",
    "Xr, yr = make_regression(n_features = 10, n_informative = np.random.randint(9)+1)\n",
    "\n",
    "# the n_informative determine the influence of a number of features to the response\n",
    "\n",
    "# instantiated previously\n",
    "Lr =  # complete the code here\n",
    "\n",
    "\n",
    "# fit (train)\n",
    "Lr. # complete the code here\n",
    "\n",
    "# Predict (test)\n",
    "y_pred = Lr. # complete the code here\n",
    "\n",
    "# loop over these coeffcients and study them\n",
    "i = 1\n",
    "for cof in Lr.coef_:\n",
    "    print('b%d=%0.2e'%(i,cof))\n",
    "    i+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "1. Any feature with a tiny coef. approaches zero can be neglected!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5 ( Boston dataset - Multiple regression)\n",
    "\n",
    "In this exercise, we want to build a better regression model using all features provided in Boston dataset. In total, the dataset has 13 features and then we may check out our estimate for 6-bedroom house while neglecting all other features. You may plot the relationship of each features against price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us check the data correlations\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "# We have already loaded the dataset in previous exercise, so let use check the correlation\n",
    "# make a dataframe from the boston loaded data\n",
    "bostondf = pd.DataFrame(data =    , columns=  ) # complete the code here\n",
    "\n",
    "# let use compute the correlation and plot it\n",
    "sns.heatmap(bostondf.corr(), vmin=-1, vmax=1, annot=True, cmap='flare')\n",
    "\n",
    "plt.tight_layout(rect=(0,0,2,2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** High multicollinear among a number of features such as DIS with  NOX, INDUS,  and AGE above -0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us check each feature corrlation with prices\n",
    "for i in range(13):\n",
    "    plt.subplot(3,6,i+1)\n",
    "    plt.scatter(  ,   ) # complete the code data , target\n",
    "    plt.xlabel(boston.feature_names[i])\n",
    "    plt.ylabel('price')\n",
    "    \n",
    "plt.tight_layout(rect=(0,0,2.5,2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:** not all features are effective and has linear relationship with price. We can work on them a little to fix those that has high skewed relationship using some transformation such as log. (left for your to explore that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us assume, you work a little more on the data and now you're ready to work on and build the regression model\n",
    "# Build an LR model\n",
    "\n",
    "# instantiate the model\n",
    "Lr2 = #complete the code here\n",
    "\n",
    "# train it with RM data (index 5) - [:,None] we can use reshape(-1,1)\n",
    "Lr2.fit(  ,    ) #complete the code here\n",
    "\n",
    "print('training finished, and a LR model is created with all features as input ..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over these coeffcients and study them\n",
    "i = 1\n",
    "for cof in Lr2.coef_:\n",
    "    print('b%d=%0.2e'%(i,cof))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what is the price of a house with 6-bedroom, assuming we know nothing about the other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To estimate a new house, we need to input the value between two brackets [[value ]]\n",
    "# remember this model expects values for other feature, let zero them out but not rm\n",
    "EstPrice = Lr2.predict(  )  #complete the code here\n",
    "\n",
    "print(\"My program estimates 6-bedroom house's price as:{0:0.2f}K$\".format(EstPrice[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "That is better price given 6-bedroom in boston and using a model that consider other 12 features will estimate the house price more than double the previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how about get the minimum value per feature and check out what price will have\n",
    "\n",
    "# get min value of each feature\n",
    "sample_min = np.min( boston.data   , axis=0).reshape(1,-1) # complete the code here\n",
    "\n",
    "EstPrice = Lr2.predict (     ) # complete the code here\n",
    "print(\"My program estimates the modest house's price as:{0:0.2f}K$\".format(EstPrice[0]))\n",
    "\n",
    "\n",
    "\n",
    "print('\\nFeatures are as follow:')\n",
    "i=0\n",
    "for ft in boston.feature_names:\n",
    "    print(ft, '%0.2e'%sample_min[0][i])\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='Question4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6 ( How good our regression model is? )\n",
    "\n",
    "In machine learning, we need to have a measure that is indicating a level of model goodness. Now, we want to evaluate the previous models and use 80% of data to rebuild them. The 20% of the data should be used for testing (to report performance). \n",
    "\n",
    "In this exercise, we are going to compute the $R^2$ for each model we build to pick the best one. \n",
    "\n",
    "\n",
    "\n",
    "[Return to Table of Contents](#TableOfContents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# let use the Exercise 1  data and separate it into train and test\n",
    "\n",
    "\n",
    "# Generate indices \n",
    "indecies = np.arange(len(X))\n",
    "\n",
    "# sampling using random package to sample traing samples and rest for testing (unique indecies)\n",
    "tr_ind = random.sample(list(indecies), int (np.round((len(X)) * 0.8) )) # 80% training and 20% testing\n",
    "ts_ind = np.delete(indecies, tr_ind).astype(int)\n",
    "\n",
    "\n",
    "# Divide the data\n",
    "X_train = X[   ]; X_test  = X[    ] # complete the code here\n",
    "y_train = y[   ]; y_test  = y[    ] # complete the code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** Since the data has no timestamps among its samples, we can pick randomly samples to for training and testing. This is not the case if we have timestamped data such as stock market. In the later case, we need to keep track on order! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training and testing data on the same plot\n",
    "plt.figure(figsize=[8,5])\n",
    "\n",
    "plt.scatter(    ,   , c='g', label='Training') # complete the code here\n",
    "plt.scatter(   ,   ,  c='k', label='Testing') # complete the code here\n",
    "\n",
    "plt.title('Dataset 1', fontsize=18)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Task3: Perform leanring on the training dataset\n",
    "# This means estimating the coeficients of the linear regression\n",
    "# Make a new model\n",
    "#instantiate a regression model\n",
    "Lr =    # complete the code here\n",
    "\n",
    "# train the model using the trianing data\n",
    "Lr.  # complete the code here\n",
    "\n",
    "# show the coefficients of the regression model\n",
    "print('b0={0:0.2f},  b1={1:0.2f}'.format(  ,  ))  # complete the code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find responses of the testing dataset\n",
    "y_pred= Lr.predict(  )  # complete the code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the results \n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "# scatter plot the training data\n",
    "plt.scatter(X_train,y_train, c='g', label='traing')\n",
    "\n",
    "# plot the lr model\n",
    "plt.plot(X_train,Lr.predict(X_train[:, None]), c='r', label='Lr model' )\n",
    "plt.title('Training space', fontsize=16)\n",
    "plt.xlabel('Idependent Variable', fontsize=14)\n",
    "plt.ylabel('Response', fontsize=14)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "# scatter plot the training data\n",
    "plt.scatter(X_test,y_test, c='k', label='testing')\n",
    "plt.scatter(X_test,Lr.predict(X_test[:, None]), c='m', label='predicted' )\n",
    "plt.title('Testing vs. predicted', fontsize=16)\n",
    "plt.xlabel('Idependent Variable', fontsize=14)\n",
    "plt.ylabel('Response', fontsize=14)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "# scatter plot the training data\n",
    "plt.plot(y_test,Lr.predict(X_test[:, None]), c='m',linestyle='--'  )\n",
    "plt.title('True-predict correlation', fontsize=16)\n",
    "plt.xlabel('True response', fontsize=14)\n",
    "plt.ylabel('Predicted response', fontsize=14)\n",
    "\n",
    "plt.tight_layout(rect=(0,0,1.9,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from the results above it seem good model, but we can compute the R-squared to have some value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the $R^2$\n",
    "\n",
    "# we can compute the r-squared for the training set to let us \n",
    "# how good or bad the model expalined the training sample variance \n",
    "# training R-squared\n",
    "y_pred = Lr.predict(X_test[:, None]) \n",
    "print('Coefficient of determination:{0:0.2f}'.format(r2_score( y_train,    )) ) # complete the code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can compute the r-squared for the testing set to tell us \n",
    "# something about the predictive quality of your model\n",
    "# testing R-squared \n",
    "print('Coefficient of determination:{0:0.2f}'.format(r2_score( y_test,    )) ) # complete the code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared = 0.93 is so good as a result\n",
    "\n",
    "**Note:** Please note the results that you will compute depends on the samples that you pick randomly. In some cases it won't be good!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual plot : as this dataset is small and we know it doesn't have Heteroscedastic data\n",
    "\n",
    "# dash line at level zero\n",
    "\n",
    "res = y_test - y_pred # complete the code here\n",
    "plt.scatter(     ,     , c='m') # complete the code here (2 params)\n",
    "plt.axhline(y=0, c='r', linestyle='--')\n",
    "\n",
    "\n",
    "plt.xlabel('fitted')\n",
    "plt.ylabel('residual')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Seabron has a function residplot\n",
    "res = y_test - y_pred\n",
    "sns.residplot(x=  , y=     , color = 'm') # complete the code here (2 params)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Due to limited data, we cannot say that the point (7.8, 2.4) is outlier. In the case above, we are zoomed in the results, we need larger test sample. \n",
    "\n",
    "**Note:**\n",
    "However, in such a scenario, we may infer that there is heteroscedasticity in the dataset and could not be appropriate for regression!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7 ( Build and evaluate regression model using boston dataset)\n",
    "\n",
    "Repeat the above analysis, and study the results for boston dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us generate random mask to pick some samples for training and other for testing\n",
    "import random\n",
    "\n",
    "# Generate indecies \n",
    "indecies = np.arange(len(boston.target))\n",
    "\n",
    "# sampling using random package to sample traing samples and rest for testing (unique indecies)\n",
    "tr_ind = random.sample(list(indecies), int (np.round((len(boston.target))* 0.8) ))\n",
    "ts_ind = np.delete(indecies, tr_ind).astype(int)\n",
    "\n",
    "\n",
    "# Divide the boston dataset into training and testing\n",
    "boston_X_train = boston.data[  ]; boston_X_test  = boston.data[  ] # complete the code here\n",
    "boston_y_train = boston.target[  ];  boston_y_test  = boston.target[ ] # complete the code here \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This means estimating the coeficients of the linear regression\n",
    "# Make a new model\n",
    "\n",
    "# instantiate the model\n",
    "Lr =  LinearRegression()\n",
    "\n",
    "# train the model\n",
    "Lr.fit(  ,  ) # complete the code here (2 params)\n",
    "print('b0={0:0.2f}'.format(Lr.intercept_))\n",
    "\n",
    "\n",
    "i = 1\n",
    "for cof in Lr.coef_:\n",
    "    print('b%d=%0.2f'%(i, cof))\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find responses of the testing dataset\n",
    "y_pred= Lr.predict(  ) # complete the code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the results \n",
    "\n",
    "# scatter plot the training data\n",
    "plt.scatter(boston_y_test, Lr.predict(boston_X_test), c='g'  )\n",
    "\n",
    "# sort to avoid chaos in plotting the predictive power line\n",
    "list1, list2 = zip(*sorted(zip(boston_y_test, y_pred))) \n",
    "plt.plot(list1,list2, c='m',linestyle='--'  )\n",
    "\n",
    "\n",
    "plt.title('True-predict correlation', fontsize=16)\n",
    "plt.xlabel('True response', fontsize=14)\n",
    "plt.ylabel('Predicted response', fontsize=14)\n",
    "\n",
    "plt.tight_layout(rect=(0,0,1.3,1.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to be perfect it should be so linear!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the $R^2$\n",
    "\n",
    "# we can compute the r-squared for the training set to let us \n",
    "# how good or bad the model expalined the training sample variance \n",
    "# training  r2_score\n",
    "print('Coefficient of determination:{0:0.2f}'.format(  ) ) # complete the code here (2 params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can compute the r-squared for the testing set to tell us \n",
    "# something about the predictive quality of your model\n",
    "# testing r2_score\n",
    "print('Coefficient of determination:{0:0.2f}'.format( ) ) # complete the code here (2 params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared = 0.75 is a good as a result\n",
    "\n",
    "**Note:** Please note the results that you will compute depends on the samples that you pick randomly. In some cases it won't be good!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual plot : as this dataset is small and we know it doesn't have Heteroscedastic data\n",
    "plt.axhline(y=0, c='r', linestyle='--')\n",
    "res =  # complete the code here \n",
    "plt.scatter( ,   , c='m')  # complete the code here (2 params)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Seabron has a function residplot\n",
    "res =  # complete the code here \n",
    "sns.residplot(x=  , y=    ,color = 'm')  # complete the code here \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "residuals are scattered around the ‘0’ line, there is no pattern, and points are not based on one side so there’s no problem of heteroscedasticity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may study further the samples that produced residuals less than -15 and above 10 in the above figure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the predictive error rate\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "print('MAE: Error rate = %0.2f'% mean_absolute_error(boston_y_test, y_pred))\n",
    "print('MSE: Error rate = %0.2f'% mean_squared_error(boston_y_test, y_pred))\n",
    "print('RMSE: Error rate = %0.2f'% np.sqrt(mean_squared_error(boston_y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='Question6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8 : ( Nonlinear Regression )\n",
    "\n",
    "Suppose you have a new dataset and asked to build the regression model. First, thing you might perform is to visualize the data. The figure showed a nonlinear relationship between the independent variable and the response. Therefore, you decided that a simple linear regression will not work well in this domain. \n",
    "\n",
    "1. Develop the code below to perform polynomial regression on the data. Let say, you decided to build quadratic and polynomial (degree 4) models\n",
    "2. Which model you will choose to keep for future use? Why?\n",
    "\n",
    "[Return to Table of Contents](#TableOfContents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To expand our dependent variable\n",
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "\n",
    "# let us generate another dataset\n",
    "Xp = np.random.randn(30)\n",
    "Xp = np.sort(Xp)\n",
    "\n",
    "# each time your run this we have different response!\n",
    "ym = np.random.randint(10) + np.random.randint(10) * Xp +  Xp ** np.random.randint(10)\n",
    "plt.scatter(Xp, ym)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to run the cell above few times to get nonlinear data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is how we can use pipelines. \n",
    "# since we have a transformation followed by modeling, we can stack them together \n",
    "# Then, the same behavior is maintained, we need to call fit and then predict the new data\n",
    "# It is much more organized as we don't need to double-check our transformation parameters again\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "mdls = []\n",
    "for dg in range(1,5, 1):\n",
    "    \n",
    "    # make pipeline transformation, estimator\n",
    "    Lr = make_pipeline(   ,    )  # complete the code here  (2 params)\n",
    "    \n",
    "    Lr.fit(Xp.reshape(-1,1), ym)\n",
    "    \n",
    "    # append the new model to mdls\n",
    "    mdls.   # complete the code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the Polynomial Regression results\n",
    "c = ['g', 'k', 'r','b']\n",
    "i = 0\n",
    "\n",
    "# plot multiple models\n",
    "for Lr in mdls:\n",
    "    plt.scatter(Xp, ym, color = 'm')\n",
    "    plt.plot(Xp, Lr.predict(Xp.reshape(-1,1)), c = c[i], label='degree('+ str(i+1) + ')', linestyle='--' )\n",
    "    i +=1\n",
    "    \n",
    "    \n",
    "plt.legend( fontsize=20)\n",
    "plt.xlabel('X', fontsize=20)\n",
    "plt.ylabel('Y', fontsize=20)\n",
    "plt.tight_layout(rect=(0,0,2,2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6. part2:** In the above case, we may select the quadratic model.\n",
    "Why: the polynomial model with that high degree is overfitting the data. This is not really learning but it is kind of memorizing the training. The learning should have some kind of flexibility that is not too much overfitting with the training data and leave some room for minor errors. Therefore, in future we hope our learned model will still be able to produce acceptable performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='Question7'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9: Piecewise Regression\n",
    "\n",
    "Let us reuse the data generated in the previous exercise (8) and use splinetransformation instead of polynomial regression to build a regression model\n",
    "\n",
    "\n",
    "[Return to Table of Contents](#TableOfContents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To expand our dependent variable\n",
    "from sklearn.preprocessing import SplineTransformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Initiate the transformation model and transform\n",
    "\n",
    "# instantiate the Spline transformer with degree 2 and 3 knots\n",
    "splines = SplineTransformer(  ,  ) # complete the code here  (2 params)\n",
    "\n",
    "# trsnform the data using splines transformer  Xp data\n",
    "Xs = splines.   # complete the code here  \n",
    "\n",
    "\n",
    "# 3. build the a regression model \n",
    "lrs = LinearRegression().fit(Xs, ym) \n",
    "\n",
    "# 4. predict y  (training)\n",
    "y_pred = lrs.predict( )   # complete the code here  \n",
    "\n",
    "# plot the results\n",
    "plt.scatter(Xp, ym, color = 'g')\n",
    "plt.plot(Xp, y_pred, c = 'r', label='spline', linestyle='--' )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to transform data into concave\n",
    "def Concave(x):\n",
    "    return 1/(1+25*x**4)\n",
    "\n",
    "# make example data\n",
    "Xc = np.linspace(-1,1,50)\n",
    "yc = Concave(Xc) + np.random.normal(0, 0.2, len(Xc))\n",
    "\n",
    "m1 = np.ones(30)\n",
    "m1 = np.append(m1, np.zeros(20) )\n",
    "np.random.shuffle(m1)\n",
    "msk = np.array(m1, dtype= bool)\n",
    "\n",
    "X_tr = Xc[msk].flatten()\n",
    "y_tr = yc[msk].flatten()\n",
    "X_ts = Xc[np.logical_not(msk)].flatten() \n",
    "y_ts = yc[np.logical_not(msk)].flatten() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# let us build a poly model to deal with concave data\n",
    "# stp1: transform the data into higher degree\n",
    "Qaud_reg = PolynomialFeatures( ) # configure the transform\n",
    "\n",
    "# transform the data train\n",
    "X_Qaud    =Qaud_reg.fit_transform(  ) # complete the code here\n",
    "\n",
    "# instantiate the simple model\n",
    "lrQ = LinearRegression()\n",
    "\n",
    "# train the model using the transformed data\n",
    "lrQ.fit(   ,    )  # complete the code here\n",
    "\n",
    "# model coefs \n",
    "print(      ) # complete the code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To to predict\n",
    "#1- you need to transform the new raw data using our transformation model\n",
    "#2- use the transformed data to get the new reponss\n",
    "\n",
    "# transform the data using the same model created in training above\n",
    "new_points = Qaud_reg.fit_transform(   ) # complete the code here\n",
    "\n",
    "# show the predicted error\n",
    "print('Error MAE:',    ) # complete the code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data and model\n",
    "plt.figure(figsize = (8,4))\n",
    "\n",
    "# predicted training data\n",
    "lrQy_pred = lrQ.predict(X_Qaud)\n",
    "\n",
    "plt.scatter(   ,   , c='m')   #training: complete the code here (X_tr, X_ts)\n",
    "plt.plot   (   ,   , c='g') #model: complete the code here\n",
    "plt.scatter(   ,   , c='k')   #testing: complete the code here\n",
    "\n",
    "plt.title('Data_Degree: 4, Model_Degree: 3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spline regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the results using spline\n",
    "\n",
    "#Spline let us try 2 knots with degree 2 (less complex model)\n",
    "splines = # complete the code here\n",
    "\n",
    "# transform\n",
    "Xstr = splines. # complete the code here\n",
    "\n",
    "\n",
    "# build the a regression model using transformed data \n",
    "lrs = LinearRegression().fit(Xstr, y_tr)\n",
    "\n",
    "# predict y (testing)\n",
    "# transform the testing data\n",
    "Xsts = # complete the code here\n",
    "\n",
    "# predict the response\n",
    "y_pred = # complete the code here\n",
    "\n",
    "# plot the results\n",
    "plt.figure(figsize = (8,4))\n",
    "\n",
    "plt.scatter(X_tr, y_tr, color = 'g')\n",
    "plt.plot(X_tr, y_pred , c = 'r', label='spline', linestyle='--' )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Error:',mean_absolute_error(y_ts, y_pred ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Better error results with less complex model only 2 degree model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='Question8'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 10  (Regularization)\n",
    "\n",
    "Model generalization is our ultimate goal when building a machine learning model. The model that we are happy of its performance during validation, should also makes happy during testing. However, due to a problem called overfitting, the trained model is so perfect during training, but not at the time of testing. This is could be due to training the model so much to the point that the model remembered the exact training samples(aka. learned the data noise). On the other hand, having limited training data make cause an issue of overfitting! \n",
    "\n",
    "In any case, a remedy to overfitting is to regularize the model during training stage. What happens in regularization is that the algorithm penalize the less influential model's parameters (i.e., feature) by reducing its value to zero in some cases. Therefore, if the model's parameter is zeroed that means the feature associated with that parameter is completed ignored by the model!\n",
    "\n",
    "In this exercise, we want to build a regularized regression models. As presented in the slides, we will study both Ridge and LASSO regression or L2 and L1 regularization respectively.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[Return to Table of Contents](#TableOfContents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let us borrow the dataset generated in Exercise 1 (X, and y)\n",
    "\n",
    "# visualize the data\n",
    "plt.figure(figsize=[8,5])\n",
    "plt.scatter(X_train,y_train, c='g', label='Training')\n",
    "plt.scatter(X_test,y_test,  c='k', label='Testing')\n",
    "plt.title('Dataset 1', fontsize=18)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort X and y simultaneously\n",
    "X_train_sorted, y_train_sorted = zip(*sorted(zip(X, y)))\n",
    "\n",
    "# convert them into numpy array\n",
    "X_train_sorted = np.array(X_train_sorted)\n",
    "y_train_sorted = np.array(y_train_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us pick the first two samples to build the regression model\n",
    "# limited training data\n",
    "X_train2 = X_train_sorted[:2]\n",
    "y_train2 = y_train_sorted[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us build a regression model on this data study behavior\n",
    "\n",
    "# build a model using limited training data (regression)\n",
    "Lr = # complete the code here\n",
    "\n",
    "# predict the response\n",
    "y_pred = # complete the code here\n",
    "\n",
    "# let us check the model\n",
    "# visualize the data\n",
    "plt.figure(figsize=[8,5])\n",
    "\n",
    "plt.scatter(X_train2, y_train2, c='m', label='Training')\n",
    "plt.plot(X_train2, y_pred,  c='r', label='model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, if we compute the training score using this model, it must be perfect\n",
    "print ('R-sqaured: %0.2f'% Lr.score(X_train2.reshape(-1,1), y_train2) )\n",
    "print ('RMSE: %0.2f'% np.sqrt (mean_squared_error(y_train2, Lr.predict(X_train2.reshape(-1,1)) ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**That is just perfect**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# know let us check the performance on the testing dataset (we omitting the validation stage here)\n",
    "print (  ) # complete the code here for testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error is no where near zero as the training, let us visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the model and testing data\n",
    "plt.figure(figsize=[8,5])\n",
    "plt.scatter(    ,    , c='m', label='testing') # complete the code here for testing data\n",
    "plt.scatter(    ,    , c='g', label='Training') # complete the code here for limited training  data\n",
    "\n",
    "# extended the model  Lr model\n",
    "plt.plot(       ,    ,  c='r', label='model') # complete the code here for whole traing\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression line is way far from the right position!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the data\n",
    "plt.figure(figsize=[8,5])\n",
    "plt.scatter(     ,     , c='m', label='Original training') # complete the code here for whole training data\n",
    "plt.scatter(    ,      , c='g', label='limited Training') # complete the code here for limited training  data\n",
    "\n",
    "# extended the model \n",
    "plt.plot(     ,      ,c='r', label='model') # complete the code here for whole traing\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from this figure, the magenta data points are not considered in the training, so the model have a wrong direction. We can reduce the effect or fix this by penalizing the slope of this regression line. To do that, we need to regularize.  let us know check the Ridge and then Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ridge and lasso from linear_model\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us build a regression model on this data study behavior\n",
    "# set the model alpha to small number as 0.008\n",
    "Lridge = Ridge(   ) # complete the code here\n",
    "\n",
    "# train the model\n",
    "Lridge.fit( ,  ) # complete the code and use limited training data\n",
    "\n",
    "# let us check the model\n",
    "# visualize the data\n",
    "plt.figure(figsize=[8,5])\n",
    "\n",
    "# data\n",
    "plt.scatter(X_train2,y_train2, c='g', label='Training')\n",
    "# model\n",
    "plt.plot(    ,     ,  c='r', label='model') # complete the code here\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that the regression line know isn't perfect on the data, we hope our regression line will follow the future trend. Let us check the performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the data\n",
    "plt.figure(figsize=[8,5])\n",
    "\n",
    "plt.scatter(     ,    , c='m', label='Original training') # complete the code here\n",
    "plt.scatter(  ,    , c='g', label='limited Training') # complete the code here limited training data\n",
    "\n",
    "# the latest model \n",
    "plt.plot(      ,    ,  c='r', label='model') # complete the code here \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let us check out the metrics\n",
    "print ('Training R-sqaured: %0.2f'% Lridge.score(X_train2.reshape(-1,1), y_train2) )\n",
    "print ('Training RMSE: %0.2f'% np.sqrt (mean_squared_error(y_train2, Lridge.predict(X_train2.reshape(-1,1)) ) ) )\n",
    "# know let us check the performance on the testing dataset (we omitting the validation stage here)\n",
    "print ('Testing RMSE: %0.2f'% np.sqrt (mean_squared_error(y_test, Lridge.predict(X_test.reshape(-1,1)) ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "The R-squared is small compared to the previous, but the errors are reduced for both testing which is great success!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can develop similar thing, but not needed, the solution manual will show the code\n",
    "alpha = np.arange(0, 0.0085, 0.0085/16)\n",
    "for i in range(16):\n",
    "    # let us build a regression model on this data study behavior\n",
    "    \n",
    "    # complete the code here  mult-line\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "plt.tight_layout(rect=(0,0,1.8, 2.5))    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso** can be used similarly to reach the same results. The only different between Lasso and Ridge is the severe effect of lasso on the parameters. It could zero them out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may parctice with lasso and elastic net algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='Question9'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='Question10'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A:(advertising and return)** code solution is left for you to study \n",
    "\n",
    "Suppose there is a company that has limited budget for advertisements in this year.\n",
    "Usually, they use three media to do marketing (TV, Newspapers, and Radio). \n",
    "However, due to the limited budget they want to select one media to promote their products this year\n",
    "\n",
    "**source:** http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv\n",
    "\n",
    "[Return to Table of Contents](#TableOfContents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data into a DataFrame\n",
    "adsData = pd.read_csv('Advertising.csv')\n",
    "adsData.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "adsData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adsData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us check if there is missing data \n",
    "adsData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us visualize the data\n",
    "sns.pairplot(adsData,  palette='flare') #rocket_r, magma,viridis,crest,flare\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "variables **TV and  radio** seem to have a positive correlation with **Sales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(adsData.corr(), annot=True,  cmap='flare')\n",
    "plt.tight_layout(rect=(0,0,2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the Sales column, we can see that TV has the highest correlation with Sales!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the relationship between the features and the response using scatterplots\n",
    "sns.pairplot(adsData, x_vars=['TV','radio','newspaper'], y_vars='sales', height=5, aspect=0.7)\n",
    "plt.tight_layout(rect=(0,0,1.5,1.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How should we spend our advertising money in the future?\n",
    "The plots shown above, illustrates the past relationship between ads. spent and sales. Unfortunately, our company has limited budget this time and want to be wisely spend it on the right media. \n",
    "\n",
    "\n",
    "#### This general question might lead you to more specific questions:\n",
    "\n",
    "Is there a relationship between ads and sales?\n",
    "\n",
    "1. How strong is that relationship?\n",
    "\n",
    "1. Which ad types contribute to sales?\n",
    "\n",
    "1. What is the effect of each ad type on sales?\n",
    "\n",
    "1. Given ad spending in a particular media, can sales be improved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Linear Regression\n",
    "\n",
    "It seems that TV media ads has a linear relationship with sales. Let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us try TV Media\n",
    "XTV = adsData['TV'].values\n",
    "XRd = adsData['radio'].values\n",
    "XNS = adsData['newspaper'].values\n",
    "y = adsData['sales'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Sklearn Linear Regression will not work on 1d array, you need to slice the are to be 2d\n",
    "lrTV = LinearRegression() \n",
    "lrTV.fit(XTV[:, None],y) \n",
    "\n",
    "lrRd = LinearRegression() \n",
    "lrRd.fit(XRd[:, None],y) \n",
    "\n",
    "lrNS = LinearRegression() \n",
    "lrNS.fit(XNS[:, None],y) \n",
    "\n",
    "print('R-squared (TV Model)', lrTV.score(XTV[:, None],y))\n",
    "print('R-squared (Radio Model)', lrRd.score(XRd[:, None],y))\n",
    "print('R-squared (Newspaper Model)', lrNS.score(XNS[:, None],y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above case, we may turst TV model more than others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred= lrTV.predict(XTV[:,None]);\n",
    "y2_pred= lrRd.predict(XRd[:,None]);\n",
    "y3_pred= lrNS.predict(XNS[:,None]);\n",
    "\n",
    "plt.figure(figsize = (15,3) )\n",
    "plt.subplot(1,3, 1)\n",
    "plt.scatter(XTV,y)\n",
    "plt.plot(XTV,y1_pred, c='r')\n",
    "plt.title('TV')\n",
    "\n",
    "plt.subplot(1,3, 2)\n",
    "plt.scatter(XRd,y)\n",
    "plt.plot(XRd,y2_pred, c='r')\n",
    "plt.title('Radio')\n",
    "\n",
    "\n",
    "plt.subplot(1,3, 3)\n",
    "plt.scatter(XNS,y)\n",
    "plt.plot(XNS,y3_pred, c='r')\n",
    "plt.title('Newspaper')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we got a budget of 50K$ how about using it only on TV media\n",
    "y1_pred= lrTV.predict([[50]]) # \n",
    "y2_pred= lrRd.predict([[50]]) # \n",
    "y3_pred= lrNS.predict([[50]]) # \n",
    "\n",
    "print('Expected Sales:\\nUsing TV\\t({0})\\nUsing Radio\\t({1})\\nUsing Newspaper\\t({2})'.format(y1_pred[0], y2_pred[0], y3_pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** even other models than TV have shown higher sales, we may not trust them according to the models R-squared!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us check residual plot (training) of these models\n",
    "res = y- lrTV.predict(XTV[:,None])\n",
    "sns.residplot(x= lrTV.predict( XTV[:,None]), y=res )\n",
    "plt.xlabel('prediction')\n",
    "plt.ylabel('residual')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us check residual plot (training) of these models\n",
    "res = y- lrRd.predict(XRd[:,None])\n",
    "sns.residplot(x= lrRd.predict( XRd[:,None]), y=res )\n",
    "plt.xlabel('prediction')\n",
    "plt.ylabel('residual')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us check residual plot (training) of these models\n",
    "res = y- lrNS.predict(XNS[:,None])\n",
    "sns.residplot(x= lrNS.predict( XNS[:,None]), y=res )\n",
    "plt.xlabel('prediction')\n",
    "plt.ylabel('residual')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** No hetroscedacitty issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us understand TV heteroscedacity issue \n",
    "for val in range(5,100,10):\n",
    "    print('Ads amount: ', val,'$', '\\texepected sales: %0.2f'%lrTV.predict([[val]])[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not great, as we increase our budget from 50 to 100, we increased our sales by 2K (Devices for example). That is not encouraging!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Heteroscedacity**\n",
    "Just to be more sure, we can perform White’s Lagrange multiplier test for heteroscedasticity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import het_white\n",
    "from statsmodels.compat import lzip\n",
    "\n",
    "res = y- lrTV.predict(XTV[:,None])\n",
    "keys = ['Lagrange statistic:', 'LM test\\'s p-value:', 'F-statistic:', 'F-test\\'s p-value:']\n",
    "xxxx = np.ones(len(XTV))\n",
    "results = het_white(res, np.append(xxxx.reshape(-1,1) , XTV.reshape(-1,1), axis=1) )  \n",
    "lzip(keys, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see that the p-value is very small, therefore, we accepts the null hypothesis and confirm that there is potential heteroscedasticity in TV dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = y- lrNS.predict(XNS[:,None])\n",
    "keys = ['Lagrange statistic:', 'LM test\\'s p-value:', 'F-statistic:', 'F-test\\'s p-value:']\n",
    "xxxx = np.ones(len(XNS))\n",
    "results = het_white(res, np.append(xxxx.reshape(-1,1) , XNS.reshape(-1,1), axis=1) )  \n",
    "lzip(keys, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see that the p-value is >0.05, therefore, we reject the null hypothesis and confirm that there is no potential heteroscedasticity in Newspaper dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There two  pupolar ways to overcome heteroscedacity or at least reduce its effects \n",
    "#1. log transform your data, \n",
    "#2. use weighted linear regression\n",
    "\n",
    "# perform log transform\n",
    "XTV_log = np.log(XTV)\n",
    "\n",
    "lrTV = LinearRegression() \n",
    "lrTV.fit(XTV_log[:, None],y) \n",
    "\n",
    "print('R-squared (TV Model)', lrTV.score(XTV_log[:, None],y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us check residual plot (training) of these models\n",
    "res = y - lrTV.predict(XTV_log[:,None])\n",
    "sns.residplot(x= lrTV.predict( XTV_log[:,None]), y=res )\n",
    "plt.xlabel('prediction')\n",
    "plt.ylabel('residual')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems not working so great, but at least it reduces the early tail in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted\n",
    "lrTV = LinearRegression() \n",
    "lrTV.fit(XTV[:, None],y, sample_weight= 1.0/XTV) \n",
    "\n",
    "print('R-squared (TV Model)', lrTV.score(XTV[:, None],y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us check residual plot (training) of these models\n",
    "# we need to compute the weighted residual now\n",
    "res = np.sqrt(1/XTV) * (y- lrTV.predict(XTV[:,None]))\n",
    "sns.residplot(x= lrTV.predict( XTV[:,None]), y=res )\n",
    "plt.xlabel('prediction')\n",
    "plt.ylabel('residual')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Expected sales form investing 50K on TV', lrTV.predict([[50]])[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**observation:**\n",
    "\n",
    "So instead of 9.5 sales, it seems we'll have only 7.5 sales from this model!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multi linear model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using all features at once\n",
    "data = adsData[['TV', 'radio', 'newspaper']]\n",
    "# y is as previous\n",
    "LR = LinearRegression()\n",
    "LR.fit(data.values, y, sample_weight=1.0/XTV )\n",
    "y_pred= LR.predict([[50, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= LR.predict([[50, 0, 0]])\n",
    "print('Expected Sales:\\nUsing TV\\t({0})'.format(y_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= LR.predict([[0, 50, 0]])\n",
    "print('Expected Sales:\\nUsing Radio\\t({0})'.format(y_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= LR.predict([[0, 0, 50]])\n",
    "print('Expected Sales:\\nUsing Newspaper\\t({0})'.format(y_pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above results make sense, since TV or Newspapers could the highest to attract people for sales, less annoucements are heard in Radio stations these days (personal observation :) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B:**  (Car Purchasing dataset) Code is available in solution manual\n",
    "\n",
    "A car agency wants to data scientist to develop a model that guess the amount a customer is willing to pay for the new car that have successful deals. The data scientist will have access to customer profiles that include annual salary, credit card debt, net-worth besides nationality, gender etc. With such information the data scientist is required to build a model that estimates a value that a customer would agree. \n",
    "\n",
    "**Source:** https://www.kaggle.com/datasets/dev0914sharma/car-purchasing-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "carsData = pd.read_csv('Car_Purchasing_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the trianing data\n",
    "carsData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us check categorical variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only USA is listed in Country column. Therefore, we can remove this column as well as Customer Name and e-mail. \n",
    "\n",
    "**Note:** In case of categorical data, we may encode the variable using pd.get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us visualize the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "variables **Net worth, Age, and Salary** seem to have a positive correlation with **Car Purchase Amount**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# correlation heat map\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "\n",
    "No multicolinear among variables. However, Age, salary, and net worth seem to have higher correlation with **Car Purchase Amount** (target var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show correlation with Purchase Amount\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No futher preprocessing is needed** we can start build a regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**load data**\n",
    "The carsData_train and carsData_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us load the prepraed training and test datasets\n",
    "XX_train = \n",
    "XX_test ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing or na entries - training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing or na entries - testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us drop column Index from the load train and test data files\n",
    "#drop Index column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check data - training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regression model - train - and compute R-squared\n",
    "lm =  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared almost 1, which means good model, let us check on what this model depends by looking at the coeff.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us check the model coef as shown in the output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is obvious that **Age** coeficients is so strong compared to others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us test the model and compute the error \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does RMSE value above good or bad?? \n",
    "\n",
    "To answer this let's check two other things \n",
    "1. power of prediction (check relation between actual vs. predicted)\n",
    "2. show the residual plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# power of prediction plot\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# residual plot \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Seabron has a function residplot \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residuals are scattered around the ‘0’ line, there is no pattern, and points are not based on one side so there’s no problem of heteroscedasticity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 241 is okay RMSE error in this exercise, but"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** can we improve the prediction error further?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
